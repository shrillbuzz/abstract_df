%1(b)(e): axioms are not automatic; checking associativity is a skill.
%3/4: proving associativity in quotient sets is clean and common.
%7: “group” is not just ± under integer operations; structure is flexible.
%9(b): inverses in number fields; algebraic numbers as a structure.
%15: standard inverse manipulation identity.
%16: order and exponent relation; basic cyclic group intuition.
\documentclass{article}
\title{Part I - Group Theory}

\usepackage[letterpaper, margin=0.75in]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{xcolor}
\usepackage{hhline}
\usepackage[shortlabels]{enumitem}
\usepackage{amsthm}
\usepackage{bm}
\usepackage{color}    %May be necessary if you want to color links
\usepackage[bookmarks,hypertexnames=false,debug,linktocpage=true,hidelinks]{hyperref}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{titlesec}

\newcommand{\oper}{\star}
\newcommand{\reals}{\mathbb{R}}
\newcommand{\complex}{\mathbb{C}}
\newcommand{\ints}{\mathbb{Z}}
\newcommand{\posints}{\mathbb{Z}^{+}}
\newcommand{\intspos}{\posints}
\newcommand{\rats}{\mathbb{Q}}
\newcommand{\eqcl}{\overline}
\newcommand{\sqrtt}{\sqrt 2}
\newcommand{\inv}[1]{ {#1}^{-1} }
\newcommand{\abs}[1]{| #1 |}
\newcommand{\mult}{\star}
\newcommand{\iso}{\cong}
\newcommand{\set}[1]{ \{ #1 \} }
\newcommand{\id}{\textbf{1}}
\newcommand{\infy}{\infty}
\newcommand{\ntimes}[2]{\underbrace{#1}_{#2 \text{ times}}}
\newcommand{\ntimesmult}[2]{\ntimes{#1\cdots #1}{#2}}
\newcommand{\wlg}{\textit{w.l.g}}
\newcommand{\intsmodn}[1]{\ints/#1\ints}
\newcommand{\finitefield}{\mathbb{F}}
\newcommand{\finfield}{\finitefield}
\newcommand{\nozeroes}[1]{#1^{\times}}
\newcommand{\genlin}{GL}
\newcommand{\sect}[1]{\subsection{}\label{sec#1}}
\newcommand{\chap}[1]{\section{#1}}
\newcommand{\prob}[1]{\subsubsection{}\label{ex#1}}
\newcommand{\skipsubsec}{\stepcounter{subsection}}
\newcommand{\skipsec}[1]{\skipsubsec\label{sec#1}}
\newcommand{\skipsect}[1]{\skipsec{#1}}
\newcommand{\skipsubsubsec}{\stepcounter{subsubsection}}
\newcommand{\skipprob}[1]{\skipsubsubsec\label{ex#1}}
\newcommand{\probstmt}[1]{\emph{#1}\\\\}
\newcommand{\bsubprob}{\begin{enumerate}[(a)]}
\newcommand{\subprob}[2]{\item\label{ex#1#2}}
\newcommand{\esubprob}{\end{enumerate}}
\newcommand{\divides}{|}
\newcommand{\phiinv}{\inv{\phi}}
\newcommand{\comp}{\circ}
\newcommand{\exref}[1]{\ref{ex#1}}
\newcommand{\suchthat}{|}
\DeclareMathOperator{\Aut}{Aut}


\newtheorem{lemma}{Lemma}

\begin{document}
\maketitle
\tableofcontents
\section{Introduction to Groups}
\sect{Basic Axioms and Examples}
\prob{1.1}
\begin{enumerate}[(a)]
	\item No. $(5-4)-1 = 1-1 = 0$ but $5-(4-1) = 5-3 = 2$
	\item Yes.
		\begin{align*}
			(a\oper b)\oper c &= (a+b+ab)\oper c\\
			&= a+b+ab+c+(a+b+ab)c\\
			&= a+b+ab+c+ac+bc+abc & \text{Distributive property of $\reals$}\\
			&= a+b+c+bc+ab+ac+abc & \text{Commutativity of $+$ in $\reals$}\\
			&= a+b+c+bc+a(b+c+bc) \\
			&= a\oper (b+c+bc) \\
			&= a\oper (b\oper c)
		\end{align*}
	\item No. $(1\oper 2)\oper 3 = \frac{1+2}{5} \oper 3 = \frac{3}{5}\oper 3 =\frac{\frac{3}{5} + 3}{5} = \frac{18}{5}$. But $1\oper (2\oper 3) = 1\oper \frac{2+3}{5} = 1\oper 1 = \frac{1+1}{5} = \frac{2}{5}$.
	\item
		Yes.
		\begin{align*}
			[(a,b)\oper (c,d)]\oper (e,f) &= (ad+bc,bd)\oper (e,f) \\
			&= ((ad+bc)f+(bd)e,(bd)f)\\
			&= (adf+bcf+bde,bdf)\\
			&= (a(df)+b(cf+de),b(df))\\
			&= (a,b)\oper (cf+de,df)\\
			&= (a,b)\oper [(c,d)\oper (e,f)]
		\end{align*}
	\item
		No. $(1\oper 2)\oper 3 = \frac{1}{2}\oper 3 = \frac{\frac{1}{2}}{3} = \frac{1}{6}$. But $1\oper (2\oper 3) = 1\oper \frac{2}{3} = \frac{1}{\frac{2}{3}} = \frac{3}{2}$
\end{enumerate}
\skipprob{1.2}
\prob{1.3}
	\begin{align*}
		(\eqcl a + \eqcl b) + \eqcl{c} &= (\eqcl{a+b}) + \eqcl{c}\\
		&= \eqcl{(a+b)+c}\\
		&= \eqcl{a+(b+c)} & \text{associativity of $+$ in $\ints$}\\
		&= \eqcl{a}+\eqcl{b+c}\\
		&= \eqcl{a}+(\eqcl{b}+\eqcl{c})\\
	\end{align*}
\subsubsection{}\label{ex1p4}
	\begin{align*}
		(\eqcl a \cdot \eqcl b) \cdot \eqcl{c} &= (\eqcl{a\cdot b}) \cdot \eqcl{c}\\
		&= \eqcl{(a\cdot b)\cdot c}\\
		&= \eqcl{a\cdot(b\cdot c)} & \text{associativity of $\cdot$ in $\ints$}\\
		&= \eqcl{a}\cdot\eqcl{b\cdot c}\\
		&= \eqcl{a}\cdot(\eqcl{b}\cdot\eqcl{c})\\
	\end{align*}
\subsubsection{}\label{ex1p5}
$\eqcl 0$ has no multiplicative inverse 
\skipprob{1.6}
\skipprob{1.7}
\skipprob{1.8}
\prob{1.9}
	\begin{enumerate}[(a)]
		\item
		\begin{itemize}
			\item $(a+b\sqrt{2}) + (c+d\sqrt{2}) = a+b\sqrt{2} + c+d\sqrt{2} = a+c + b\sqrt{2} + d\sqrt{2} = (a+b) + (b+d)\sqrt{2} \in G$, so the operation is closed under addition.
			\item Associativity follows directly from associativity in $\reals$
			\item $0 = 0+\sqrt{2}$ is clearly an identity
			\item $-a+(-b)\sqrt{2}$
		\end{itemize}
		\item To help us, we prove the following lemma
			\begin{lemma}\label{lemma:1p1p9}
				Given $a,b \in \rats$, $a+b\sqrtt \neq 0 \iff a \neq 0$ or $b \neq 0$
			\end{lemma}
			\begin{proof}
				For $\implies$, if we had both $a,b=0$, then we'd have $a+b\sqrt{2} = 0 + 0\sqrt{2} = 0$. For $\impliedby$, assume without generality that $a\neq 0$. Then $a+b\sqrt{2} = 0$ would mean that $a=-b\sqrt{2}$. However, since $b$ is rational, $-b\sqrt{2}$ is irrational. But $a$ is rational, so they can't be equal. 
			\end{proof}
		\begin{itemize}
			
			\item Let $a,b\in\rats$ not both be zero and $c,d\in\rats$ not both be zero. Then $(a+b\sqrt{2})(c+d\sqrt{2})=ac+bc\sqrt{2}+ad\sqrt{2}+2bd=(ac+2bd) + (ad+bc)\sqrt{2}$. The result is nonzero thanks to the zero product property in $\reals$. Hence, the operation is closed under multiplication
			\item Associativity follows directly from associativity of multiplication in $\reals$
			\item The identity is clearly $1=1+0\sqrt{2}$
			\item To find an inverse, we note that the inverse of $a+b\sqrt{2}$ in $\reals$ is $\frac{1}{a+b\sqrt{2}}$ (note, we have $a+b\sqrt{2} \neq 0$). Now we "rationalize.":
				\begin{align*}
					&= \frac{1}{a+b\sqrt{2}} \\
					&= \frac{1}{a+b\sqrt{2}}(\frac{a-b\sqrt{2}}{a-b\sqrt{2}}) & \text{Possible by \cref{lemma:1p1p9}}\\
					&= \frac{a-b\sqrt{2}}{(a+b\sqrtt)(a-b\sqrtt)}\\
					&= \frac{a-b\sqrt{2}}{a^2 - 2b^2}\\
					&= \frac{a}{a^2 - 2b^2}+ \frac{-b}{a^2 - 2b^2}\sqrt{2}\\
				\end{align*}
		\end{itemize}
	\end{enumerate}
\stepcounter{subsubsection}\label{ex1p10}
\stepcounter{subsubsection}\label{ex1p11}
\stepcounter{subsubsection}\label{ex1p12}
\stepcounter{subsubsection}\label{ex1p13}
\stepcounter{subsubsection}\label{ex1p14}
\subsubsection{}\label{ex1p15}
	Clearly this holds for $n=1$. Now suppose $\inv{(a_1\cdots a_{n-1})}=\inv{a_{n-1}}\cdots\inv{a_1}$. Then
	\begin{align*}
		(\inv{a_n}\inv{a_{n-1}}\cdots\inv{a_1})(a_1\cdots a_{n-1}a_n)
		&= \inv{a_n}(\inv{a_{n-1}}\cdots\inv{a_1})(a_1\cdots a_{n-1})a_n & \text{Associativity}\\
		&= \inv{a_n}\inv{(a_1\cdots a_{n-1})}(a_1\cdots a_{n-1})a_n\\
		&= \inv{a_n}1a_n\\
		&= \inv{a_n}a_n\\
		&= 1
	\end{align*}
\subsubsection{}\label{ex1p16}
	\begin{itemize}
		\item First suppose that $x^2 = 1$
		\begin{itemize}
		\item Case: $x=1$. Then $x^1 = 1$. Hence $\abs{x}=1$
		\item Case: $x\neq 1$. Then $x^1 \neq 1$. But $x^2 = 1$. Hence $\abs{x}=2$
		\end{itemize}
		\item Now suppose $\abs{x}=1$ or $2$
		\begin{itemize}
		\item Case: $\abs{x}=1$. Then $x^1 = 1 \implies x = 1$, and $x^2=1^1=1$
		\item Case: $\abs{x}=2$. Then $x^2=1$ by definition
		\end{itemize}
	\end{itemize}
\subsubsection{}\label{ex1p17}
	\begin{align*}
		x^{n-1}x &= x^n\\
		&= 1
	\end{align*}
	Hence $x^{n-1} = \inv{x}$
\stepcounter{subsubsection}\label{ex1p18}

\subsubsection{}\label{ex1p19}
	\begin{enumerate}[(a)]
		\item \label{a}
			\begin{align*}
				x^ax^b &= (\ntimes{x\cdots x}{a})(\ntimes{x\cdots x}{b})\\
				&= \ntimes{x\cdots x}{a+b}\\
				&= x^{a+b}
			\end{align*}
			And
			\begin{align*}
				(x^a)^b &= \ntimes{x^a\cdots x^a}{b}\\
				&= \ntimes{\ntimes{x}{a}\cdots\ntimes{x}{a}}{b}\\
				&= \ntimes{x\cdots x}{a\cdot b}\\
				&= x^{ab}
			\end{align*}
		\item \label{b}
			Clearly works for $a=1$. Now suppose that $\inv{(x^{a-1})} = x^{-(a-1)}$. Then
			\begin{align*}
				x^{-a}x^a &= (\ntimes{\inv{x}\cdots\inv{x}}{a})x^a & \text{By definition}\\
				&= (\inv{x}\ntimes{\inv{x}\cdots\inv{x}}{a-1})x^{a-1}x \\
				&= \inv{x}x^{-(a-1)}x^{a-1}x & \text{Definition}\\
				&= \inv{x}\inv{ (x^{a-1}) }x^{a-1}x & \text{Inductive assumption}\\
				&= \inv{x}1x & \\
				&= \inv{x}x & \\
				&= 1
			\end{align*}
		\item \label{c}
			Fuck my life bro. This is more annoying that it seems.
			\begin{enumerate}[i]
				\item We first show that $x^ax^b=x^{a+b}$ for all $a,b\in\ints$. We go by cases.
					\begin{enumerate}[(1)]
						\item \label{case1} Case: $a=0$ or $b=0$. Assume $a=0$ without loss of generality. Then $x^ax^b=x^0x^b=1x^b=x^b=x^{0+b}=x^{a+b}$.
						\item \label{bothneg} Case: Both $a,b<0$. Then let $c=-a,d=-b$. Then
							\begin{align*}
								x^a x^b &= x^{-c}x^{-d}\\
								&= (\inv{x})^{c}(\inv{x})^{d} & \text{Definition}\\
								&= (\inv{x})^{c+d} & \text{By \ref{a}}\\
								&= x^{-(c+d)} & \text{Definition}\\
								&= x^{-c-d} \\
								&= x^{a+b} \\
							\end{align*}
						\item \label{case2} Case: One is negative, one is positive. Assume without loss of generality that $a<0,b>0$. We proceed by induction on $b$. We can take $b=0$ to be the base case (we've already shown it in the Case \ref{case1}) and then assume that $x^ax^{b-1}=x^{a+b-1}$. Then
							\begin{align*}
								x^ax^b &= x^ax^{b-1}x\\
								&= x^{a+b-1}x\\
							\end{align*}
							Okay, so if $a+b-1 > 0$, this is just \ref{a}. If $a+b-1=0$, this is just Case \ref{case1}. So we have to deal with the case $a+b-1<0$. Then
							\begin{align*}
								x^{a+b-1}x &= \ntimesmult{\inv{x}}{-(a+b-1)} \\
								&= \ntimesmult{\inv{x}}{1-a-b}x \\
								&= \ntimesmult{\inv{x}}{1-a-b-1} \\
								&= \ntimesmult{\inv{x}}{-a-b} \\
								&= \ntimesmult{\inv{x}}{-(a+b)} \\
								&= \ntimesmult{x}{a+b} \\
							\end{align*}
					\end{enumerate} %Cases
				\item Alright, now time for $(x^a)^b = x^{ab}$. We proceed by cases again
					\begin{enumerate}[(1)]
						\item Case: $a=0$. Then $(x^a)^b = (x^0)^b = 1^b = 1 = x^0 = x^{0b} = x^{ab}$
						\item Case: $b=0$. Then $(x^a)^b = (x^a)^0 = 1 = x^0 = x^{a0} = x^{ab}$
						\item Case: $a<0, b>0$. Let $c=-a$ Then
							\begin{align*}
								(x^a)^b &= (x^{-c})^b\\
								&= ( (\inv{x})^c)^b & \text{Definition}\\
								&=  (\inv{x})^{cb} & \text{By \ref{a}}\\
								&=  {x}^{-cb} & \text{Definition}\\
								&=  {x}^{ab}
							\end{align*}
						\item \label{lolcase} Case: $a>0,b<0$. Let $c=-b$. I REGRET DOING THIS EXERCISE. I REGRET DOING THIS EXERCISE. Then
							\begin{align*}
								(x^a)^b &= (x^a)^{-c}\\
								&= \inv{((x^a)^c)} & \text{By \ref{b}}\\
								&= \inv{((x^{ac})} & \text{By \ref{a}}\\
								&= x^{-ac} & \text{By \ref{b}}\\
								&= x^{ab}
							\end{align*}
						\item Case: $a,b < 0$. Let $c=-a$. Then
							\begin{align*}
								(x^a)^b &= (x^{-c})^b\\
								&= ((\inv{x})^c)^b & \text{Definition}\\
								&= (\inv{x})^{cb} & \text{By the previous case, Case \ref{lolcase}}\\
								&= x^{-cb} & \text{Definition}\\
								&= x^{ab} 
							\end{align*}
					\end{enumerate} %Cases
					And we're done. I regret doing this exercise. 
			\end{enumerate} %Part (c)
	\end{enumerate}
	We will use the results of this exercise without referring to it from here on.
\subsubsection{}\label{ex1p20}
	\begin{itemize}
		\item Suppose $\abs{x}=\infy$. Then suppose $\abs{\inv{x}} = n$ for $n\in\posints$. Then
			\begin{align*}
				\inv{(\inv{x})} &= (\inv{x})^{n-1} & \text{by \ref{ex1p17}}\\
				\implies x &= x^{-n+1}\\
				\implies x^{n-1}x &= x^{n-1}x^{-n+1} \\
				\implies x^{n} &= x^{n-1-n+1} \\
				&= x^{0}\\
				&= 1
			\end{align*}
			Hence $\abs{x} \leq n$, a contradiction. So we can't have $n\in\posints$, so $n=\infy$
		\item Suppose $\abs{x}=n\in\posints$. Then let $\abs{\inv{x}}=l$. Then
			\begin{align*}
				(\inv{x})^l &= x^{-l}\\
				\implies l &= \inv{(x^{l})} \\
				\implies x^l &= x^l\inv{(x^l)} \\
				\implies x^l &= 1 \\
			\end{align*}
			So $l=kn$ for some $k \in \posints$. I.e. $l \geq n$. But
				\begin{align*}
					(\inv{x})^n &= x^{-n}\\
					&= \inv{(x^n)}\\
					&= \inv{1}\\
					&= 1
				\end{align*}
				So $l \leq n$. So we must have $l=n$
	\end{itemize}
\subsubsection{}\label{ex1p21}
	Since $n$ is odd, let $n=2s+1$ for $s \in \posints$ Then
		\begin{align*}
			x^n &= x^{2s+1}\\
		\implies 1 &= x^{2s+1}\\
		\implies x &= x^{2s+2}\\
		&= x^{2(s+1)}\\
		&= (x^2)^{s+1}
		\end{align*}
\stepcounter{subsubsection}\label{ex1p22}
\subsubsection{}\label{ex1p23}
	Let $\abs{x^s}=r$. Then $(x^s)^t = x^{st} = x^n = 1$, so $r \leq t$. But note that $k=r$ is the lowest positive integer for which
		\begin{equation}
			(x^s)^k = 1
		\end{equation}
		holds. However, we showed that $k=t$ also makes the equation true, so $t\geq r$. Hence $t=r$
\stepcounter{subsubsection}\label{ex1p24}
\subsubsection{}\label{ex1p25}
	Given $a,b \in G$,
	\begin{align*}
		(ab)(ba) &= ab^2a\\
		&=a1a\\
		&= a^2\\
		&=1\\
		\implies (ab)(ab)(ba) &= ab\\
		\implies (ab)^2(ba) &= ab\\
		\implies 1(ba) &= ab\\
		\implies ba &= ab
	\end{align*}
\subsubsection{}\label{ex1p26}
	\begin{itemize}
		\item Closure under the operation is given by the definition
		\item Associativity is directly inherited from $G$
		\item Inverses exist as given by the definition
		\item The identity exists. Note that by definition, $H$ is closed under the operation and inverses. We were also given that $H$ is nonempty, so we can take some $h\in H$, and note that $\inv{h}\in H$ as well. So $h\inv{h} \in H$, i.e. $1 \in H$.
	\end{itemize}
\subsubsection{}\label{ex1p27}
	Let $H=\set{x^n | n \in \ints}$. 
		\begin{itemize}
			\item $H$ is closed under the operation. Let $x^n, x^m \in H$. then $x^nx^m = x^{n+m} \in H$.
			\item $H$ is closed under inverses. Given $x^n$, note that $x^{-n} \in H$, which is clearly its inverse.
		\end{itemize}
\stepcounter{subsubsection}\label{ex1p28}
\subsubsection{}\label{ex1p29}
	\begin{itemize}
		\item $\impliedby$: If $A, B$ abelian, given $(a,b), (c,d) \in A\times B$, we have $(a,b)(c,d)=(ac,bd)=(ca,db)=(c,d)(a,b)$
		\item $\implies$: Now assume without loss off generality that $B$ is not abelian (e.g. space of invertible matrices), and take any $b,d \in B$ such that $bd \neq db$. Then $(a,b)(c,d)=(ac,bd)$. But $(c,d)(a,b) = (ca, db) = (ac, db)$. Note that by definition of $A\times B$, since $bd\neq db$, we have $(ac,bd) \neq (ac, db)$.
	\end{itemize}
\subsubsection{}\label{ex1p30}
	$(a,1)(1,b) = (a\cdot 1, 1\cdot b) = (1\cdot a, b\cdot 1) = (1,b)(a,1)$, so these elements commute. Note let $A=\abs{a}, B=\abs{b}, l = \abs{(a,b)}$. Note that
	\begin{align*}
		1 &= (a,b)^l\\
		&= [(a,1)(1,b)]^l\\
		&= (a,1)^l(1,b)^l & \text{By the commutativity we just proved}\\ 
		&= (a^l,1)(1,b^l)\\
\iff (1,1) &= (a^l,b^l)
	\end{align*}
	Which happens iff $a^l =1, b^l = 1$. I.e. iff $l =qA=tB$, for some positive integers $q,t$. I.e. iff $l$ is a multiple of both $A$ and $B$, i.e. $l$ is a common multiple of $A,B$. But $l$ is the \textit{smallest} positive integer for which this holds, i.e. $l$ must be the \textit{least} common multiple of $A$ and $B$.
\subsubsection{}\label{ex1p31}
	We follow the hint and let $t(G) = \set{g\in G | g\neq\inv{g}}$. Note that the elements of $t(G)$ come in pairs ($g$ and $\inv{g}$), hence its cardinality must be even.\\
	Now let $g \in G-t(G)$ with $g \neq 0$. Does such an element exist? Since $1 \in t(G)$, we do have $\abs{G} > t(G)$. If $\abs{G} = t(G) + 1$, then $G$ would be odd, a contradiction. So we must have $\abs{G} \geq t(G) + 2$, i.e. $G-t(G)$ has at least one nonidentity element $g$, and for this element we have $g=\inv{g} \implies g^2 = 1$.
\subsubsection{}\label{ex1p32}
	Suppose $x^k=x^l$, with $0\leq k \leq l \leq n-1$. Then
	\begin{align*}
		x^k &= x^l\\
	\implies 1&= x^{l-k}\\
	\implies l-k &= rn
	\end{align*}
	Where $r \in Z$. Since $l \geq k$, we must have $r \geq 0$. Now suppose $r>0$. Then $l=rn+k > n-1$, a contradiction. Hence $r=0$ and $l-k=0$ i.e. $l=k$.\\
	Now if $\abs{x} > \abs{G}$, then the elements $1,x,\ldots,x^{n-1}$ would comprise $n > \abs{G}$ distinct elements in $G$, which is impossible.
\subsubsection{}\label{ex1p33}
	
		A lemma will help us here.
		\begin{lemma}\label{lemma:1p32}
			For $i=1,2,\ldots,n-1$, if $x^i=x^{-i}$, then $2i=n$.
		\end{lemma}
		\begin{proof}
			\begin{align*}
				x^i &= x^{-i}\\
				\implies x^{2i} &= 1\\
				\implies 2i &= rn & \text{for some $r\in \ints$}
			\end{align*}
			We must show that $r =1$, and we're done. If $r \leq 0$, this would contradict $1\leq i < n$.\\If $r \geq 2$, then
			\begin{align*}
				2i &= rn\\
				\implies i &= \frac{r}{2}n\\
				&> \frac{2}{2}n\\
				= n
			\end{align*}
			which again contradicts $1 \leq i < n$. So we must have $r=1$
		\end{proof}
		\begin{enumerate}[(a)]
		\item With $n$ odd, suppose $x^i = x^{-i}$. Then applying the lemma yields $2i=n$, making $n$ even, a contradiction.
		\item With $n$ even, for $\implies$, suppose $x^i = x^{-i}$. Applying the lemma again yields
			\begin{align*}
				2i &= n\\
				&= 2k\\
				\implies i &= k
			\end{align*}
		Now for $\impliedby$, suppose $i=k$. Then
			\begin{align*}
				1 &= x^n\\
				&= x^{2k}\\
				&= x^{2i}\\
				\implies x^{-i} &= x^i
			\end{align*}
	\end{enumerate}
\subsubsection{}\label{ex1p34}
	Let $n,m \in \ints$. Assume \wlg $m \geq n$. Then
	\begin{align*}
		x^n &= x^m\\
		\implies 1 &= x^{m-n}
	\end{align*}
	Since $m \geq n$, we have $m-n\geq 0$ If $m-n>0$, then $\abs{x} \leq m-n$, contradicting $\abs{x}=\infy$. Hence $m-n =0$, i.e. $m=n$
\subsubsection{}\label{ex1p35}
	Let $l \in \ints$. Then by Euclidean division, $l=kn+r$ with $0\leq r < n$. So
	\begin{align*}
		x^l &= x^{kn+r}\\
		&= x^{kn}x^r\\
		&= (x^n)^kx^r\\
		&= (1)^kx^r\\
		&= 1x^r\\
		&= x^r\\
	\end{align*}

\stepcounter{subsection}
\stepcounter{subsection}
\subsection{Matrix Groups}
\subsubsection{}\label{ex4p1}
Since $\finfield_2 = \set{0,1}$, it's straightforward to exhaust the elements of $GL_2(\finfield_2)$ by "turning on/off" the entries. These elements are:
\begin{align*}
I &= \begin{pmatrix}
1 & 0\\
0 & 1
\end{pmatrix}\\
A &= \begin{pmatrix}
0 & 1\\
1 & 0
\end{pmatrix}\\
B &= \begin{pmatrix}
0 & 1\\
1 & 1
\end{pmatrix}\\
C &= \begin{pmatrix}
1 & 0\\
1 & 1
\end{pmatrix}\\
D &= \begin{pmatrix}
1 & 1\\
0 & 1
\end{pmatrix}\\
E &= \begin{pmatrix}
1 & 1\\
1 & 0
\end{pmatrix}\\
\end{align*}
Any other possible element's determinant is 0
\subsubsection{}\label{ex4p2}
We already listed the elements above. Simple computation gives us $\abs{I}=1$, $\abs{A}=\abs{C}=\abs{D} = 2$, $\abs{B}=\abs{E}= 3$
\prob{3}
We'll take the following lemma for granted moving forward:
\begin{lemma}
In a field $F$, $0 \neq 1$
\end{lemma}
\begin{proof}
If $0=1$ in $F$, then $\nozeroes{F}=F-\set{0}$ does not contain the multiplicative identity, and therefore $\nozeroes{F}$ is not an abelian group, violating the first condition in the definition of a field.
\end{proof}
Let $x=\begin{pmatrix}1 & 1\\0 & 1\end{pmatrix}$ and $y=\begin{pmatrix}1 & 1\\1 & 0\end{pmatrix}$. Then the top left entry of $xy$ is $2=0$ but the top left entry of $yx$ is $1$. Since $1\neq 0$ in a field, $xy \neq yx$.
\subsubsection{}\label{ex4p4}
Let $n=ab$ where $a,b \neq 1$. Suppose there was some $l \in \ints$ such that
\begin{align*}
\eqcl{a}\cdot\eqcl{l} &= \eqcl{1}\\
\implies \eqcl{al} &= \eqcl{1}\\
\implies \eqcl{al} - \eqcl{1} &= \eqcl{0}\\
\implies \eqcl{al-1} &= \eqcl{0}\\
\implies al-1 &= qn & \mbox{for some integer $q$}\\
&=qab\\
\implies al-abq &= 1\\
\implies a(l-bq) &= 1
\end{align*}
Since $a \neq 1$ and $l-bq$ must be an integer, this is impossible. Thus $\eqcl{a}$ does not have a multiplicative inverse, so $\intsmodn{n}$ cannot be a field.
\subsubsection{}\label{ex4p5}
\begin{itemize}
\item $\impliedby$: If $\abs{F}=q$ is finite, then there are at most $q$ possibilities for each entry of an element from $GL_n(F)$, therefore $\abs{GL_n(F)} \leq q^{n^2}$. In fact, since the $0$ matrix is non-invertible, we can make this a strict inequality:
\begin{equation}
\abs{GL_n(F)} < q^{n^2} \label{eq:stupidineq}
\end{equation}
\item $\implies$: If $F$ is infinite consider the correspondence $\nozeroes{F} \to \genlin_n(F)$ given by 
\begin{equation}
f \mapsto \begin{pmatrix}
f & \cdots & 0\\
\vdots & \ddots & \vdots\\
0 & \cdots & f
\end{pmatrix}
\end{equation}
I.e. $f$ on the diagonal and $0$s everywhere else, in case that wasn't clear.\\
This is an injective group homomorphism, or just note that it clearly embeds $\nozeroes{F}$ into $\genlin_n(F)$ as a subgroup. Therefore, we have an infinite subgroup of $\genlin_n(F)$, making $\genlin_n(F)$ infinite.
\end{itemize}
\subsubsection{}\label{ex4p6}
Already shown in the previous exercise by by \cref{eq:stupidineq}.
\subsubsection{}\label{ex4p7}
The total number of $2\times 2$ matrices over $\finfield_p$ is clearly $p^4$ (as we went over in the above 2 exercises).\\
Now we count all the noninvertible matrices, taking note that a $2\times 2$ is noninvertible $\iff$ one row is a multiple of the other. Let's proceed by cases.
\begin{itemize}
\item Select for all the matrices whose top two entries are both nonzero: $(p-1)(p-1)$. To get the noninvertible matrices of this form, we take a multiple of the top row as the bottom row, so there are $p$ choices for the bottom row (since there are $p$ multiples of the top row), hence the total number of matrices in this case is $p(p-1)(p-1) = p^3 -2p^2+p$. The following cases proceed similarly.
\item Matrices where top-left entry is $0$ and top-right entry is nonzero: $p-1$ choices for the top row, and we take multiples for the bottom row so in total $p(p-1)$ matrices
\item Matrices where top-left entry is nonzero and top-right entry is $0$. Analagous to the above case, yielding again $p(p-1)$ matrices
\item Lastly, consider the matrices where the top entries are both $0$. Then any entries for the bottom row work. there are two entries in the bottom row, so $p^2$ matrices
\end{itemize}
Adding these all together, we get
\begin{align*}
(p^3 - 2p^2 +p) + (p^2-p) + (p^2-p) + p^2 &= p^3-2p^2+p^2+p^2+p^2+p-p-p\\
&=p^3-2p^2+3p^2-p\\
&=p^3+p^2-p
\end{align*}
We subtract this result (number of noninvertible matrices) to the total number of matrices to obtain the number of invertible matrices:
\begin{equation}
p^4 - (p^3+p^2-p) = p^4-p^3-p^2+p
\end{equation}
\subsubsection{}\label{ex4p8}
We'll also take the following lemma for granted
\begin{lemma}\label{lemma:1neq2}
In a nontrivial field $F$, $n \neq n+1$
\end{lemma}
\begin{proof}
\begin{align*}
n &= n+1\\
\implies 0 &= 1\\
\end{align*}
which we can't have in a field
\end{proof}
Let $p$ be the identity matrix except that the toprightmost entry is $1$. Let $q$ be the identity matrix except the bottomleftmost entry is $1$. The topleft entry of $qp$ is $1$ but the topleft entry of $pq$ is $2$. They cannot be equal because of the lemma, and hence $qp\neq pq$
\subsubsection{}\label{ex4p9}
The following proof works for matrices over any field $F$
\begin{align*}
[\begin{pmatrix}a & b\\c & d\end{pmatrix}\begin{pmatrix}e & f\\g & h\end{pmatrix}
]\begin{pmatrix}i & j\\k & l\end{pmatrix}
&= \begin{pmatrix}ae+bg & af+bh\\ce+dg & cf+dh\end{pmatrix}
\begin{pmatrix}i & j\\k & l\end{pmatrix}\\
&= \begin{pmatrix}aei+bgi +afk+bhk & aej+bgj+afl+bhl\\cei+dgi+cfk+dhk & cej+dgj+cfl+dhl\end{pmatrix}\\
&= \begin{pmatrix}a(ei+fk)+b(gi+hk) & a(ej+fl)+b(gj+hl)\\c(ei+fk)+d(gi+hk) & c(ej+fl)+d(gj+hl)\end{pmatrix}\\
&=
\begin{pmatrix}
a & b\\c & d
\end{pmatrix}
\begin{pmatrix}ei+fk & ej+fl\\gi+hk & gj+hl\end{pmatrix}\\
&=
\begin{pmatrix}a & b\\c & d\end{pmatrix}[\begin{pmatrix}e & f\\g & h\end{pmatrix}
\begin{pmatrix}i & j\\k & l\end{pmatrix}]
\end{align*}
\subsubsection{}\label{ex4p10}
\begin{enumerate}[(a)]
\item
\begin{equation}\label{eq:uppertriang2}
\begin{pmatrix}
a_1 & b_1\\
0 & c_1
\end{pmatrix}
\begin{pmatrix}
a_2 & b_2\\
0 & c_2
\end{pmatrix}
=
\begin{pmatrix}
a_1a_2 & a_1b_2 + b_1c_2\\
0 & c_1c_2
\end{pmatrix}
\end{equation}
Since $a_1,a_2,c_1,c_2 \neq 0$, we have $a_1a_2 \neq 0$ and $c_1c_2 \neq 0$, so the result is still in $G$ (So $G$ is closed under matrix multiplication)
\item Note: $a,c \neq 0$, and we need
\begin{align*}
\begin{pmatrix}
a & b\\
0 & c
\end{pmatrix}
\begin{pmatrix}
e & f\\
0 & g
\end{pmatrix}
&= 
\begin{pmatrix}
1 & 0\\
0 & 1
\end{pmatrix}\\
\iff
\begin{pmatrix}
ae & af+bg\\
0 & cg
\end{pmatrix}
&= 
\begin{pmatrix}
1 & 0\\
0 & 1
\end{pmatrix}\\
\end{align*}
Which is true iff the following system of equations hold
\begin{align*}
ae &= 1\\
af + bg &= 0\\
cg &= 1
\end{align*}
Since $a,c\neq 0$, we can divide by them to obtain 
\begin{align*}
e &= 1/a\\
f &= \frac{-bg}{a}\\
g &= 1/c
\end{align*}
We substitute $g = 1/c$ into the second equation to obtain $f=\frac{-b}{ca}$. Note that all the work can be connected by iffs. Hence, we have
\begin{equation}\label{eq:uppertriang2inverse}
\begin{pmatrix}
a & b\\0 & c
\end{pmatrix}^{-1}
=
\begin{pmatrix}
1/a & \frac{-b}{ac}\\0 & 1/c
\end{pmatrix}
\end{equation}
\item In exercise \ref{ex1p26} we showed that closure under the operation and inverses means that it is a subgroup
\item 
\begin{itemize}
\item Closure under multiplication: Take \cref{eq:uppertriang2} and make $c_1=a_1$ and $c_2=a_2$, so the result becomes %$\begin{pmatrix}a_1a_2 & a_1b_2 + b_1a_2\\0 & a_1a_2\end{pmatrix}$
\begin{equation}\label{eq:uppertriang2}
\begin{pmatrix}
a_1 & b_1\\
0 & a_1
\end{pmatrix}
\begin{pmatrix}
a_2 & b_2\\
0 & a_2
\end{pmatrix}
=
\begin{pmatrix}
a_1a_2 & a_1b_2 + b_1c_2\\
0 & a_1a_2
\end{pmatrix}
\end{equation}
which is clearly in $G$ because the diagonal entries are equal.
\item Closure under inverses: Take \cref{eq:uppertriang2inverse} and make $c=a$, so we get
\begin{equation}
\begin{pmatrix}
a & b\\0 & a
\end{pmatrix}^{-1}
=
\begin{pmatrix}
1/a & \frac{-b}{a^2}\\0 & 1/a
\end{pmatrix}
\end{equation}
Again, the inverse is clearly in $G$ because the diagonals are equal.
\end{itemize}
\end{enumerate}
\subsubsection{}\label{ex4p11}
\newcommand{\abcberg}{
\begin{pmatrix}
1 & a & b\\
0 & 1 & c\\
0 & 0 & 1
\end{pmatrix}}
\begin{enumerate}[(a)]
\item 
\begin{align}
XY &= 
\begin{pmatrix}
1 & a & b\\
0 & 1 & c\\
0 & 0 & 1
\end{pmatrix}
\begin{pmatrix}
1 & d & e\\
0 & 1 & f\\
0 & 0 & 1
\end{pmatrix}\\
&=
\begin{pmatrix}\label{eq:heisenberg}
1 & a+d & e+af+b\\
0 & 1 & c+f\\
0 & 0 & 1
\end{pmatrix}
\end{align}
Which is still clearly in $H(F)$, making it closed under matrix multiplication. Also note that 
\begin{equation}
YX = 
\begin{pmatrix}
1 & a+d & b+cd+e\\
0 & 1 & c+f\\
0 & 0 & 1
\end{pmatrix}
\end{equation}
Now note that
\begin{align*}
XY &= YX\\
\iff e+af+b &= b+cd+e\\
\iff af &= cd
\end{align*}
So no matter what field $F$, we're using, we can let $a,f=0$ and $c,d=1$ to obtain $XY\neq YX$. Explicitly, an example of two matrices that don't commute is:
\begin{align*}
X &= \begin{pmatrix}
1 & 0 & 0\\
0 & 1 & 1\\
0 & 0 & 1
\end{pmatrix}\\
Y &= \begin{pmatrix}
1 & 1 & 0\\
0 & 1 & 0\\
0 & 0 & 1
\end{pmatrix}
\end{align*}
\item Using \cref{eq:heisenberg}, We need
\begin{equation}
\begin{pmatrix}
1 & a+d & b+cd+e\\
0 & 1 & c+f\\
0 & 0 & 1
\end{pmatrix} = 
\begin{pmatrix}
1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 1
\end{pmatrix}
\end{equation}
i.e. we obtain a system of equations and solve:
\begin{align*}
a+d &= 0 &\iff d &= -a\\
c+f&=0 &\iff f&=-c\\
e+af+b&=0 &\iff e&=-af-b=ac-b
\end{align*}
I.e.
\begin{equation}\label{heisenberginverse}
\inv{X} =
\begin{pmatrix}
1 & -a & ac-b\\
0 & 1 & -c\\
0 & 0 & 1
\end{pmatrix}
\end{equation}
\item Let $X,Y$ be as given and let $Z = 
\begin{pmatrix}
1 & g & h\\
0 & 1 & i\\
0 & 0 & 1
\end{pmatrix}$. Then, using \cref{eq:heisenberg} again,
\begin{align*}
(XY)Z &= 
\begin{pmatrix}
1 & a+d & e+af+b\\
0 & 1 & c+f\\
0 & 0 & 1
\end{pmatrix}
\begin{pmatrix}
1 & g & h\\
0 & 1 & i\\
0 & 0 & 1
\end{pmatrix}\\
&= \begin{pmatrix}
1 & g+a+d & h+i(a+d)+e+af+b\\
0 & 1 & i+c+f\\
0 & 0 & 1
\end{pmatrix}\\
&= \begin{pmatrix}
1 & a+d+g & h+ia+id+e+af+b\\
0 & 1 & c+f+i\\
0 & 0 & 1
\end{pmatrix}\\
&= \begin{pmatrix}
1 & a+d+g & a(f+i) + b + h+id+e
0 & 1 & c+f+i\\
0 & 0 & 1
\end{pmatrix}\\
&= 
\begin{pmatrix}
1 & a & b\\
0 & 1 & c\\
0 & 0 & 1
\end{pmatrix}
\begin{pmatrix}
1 & d+g & h+id+e
0 & 1 & f+i\\
0 & 0 & 1
\end{pmatrix}\\
&= 
X[
\begin{pmatrix}
1 & d & e\\
0 & 1 & f\\
0 & 0 & 1
\end{pmatrix}
\begin{pmatrix}
1 & g & h\\
0 & 1 & i\\
0 & 0 & 1
\end{pmatrix}]\\
&= X(YZ)
\end{align*}
Given an element of $H(F)$, we have 3 entries to input, and ee have $\abs{F}$ choices for each entry, so the order is $\abs{F}^3$ (any possible combination of the three entries yields a valid element, no noninvertible matrices or anything to cut out)
\item We're going to do some prep work here. Let's study the powers of elements from $H(F)$. We note that, by computation
\begin{align*}
X &= \begin{pmatrix}
1 & a & b\\
0 & 1 & c\\
0 & 0 & 1
\end{pmatrix}\\
X^2 &= \begin{pmatrix}
1 & 2a & 2b+ac\\
0 & 1 & 2c\\
0 & 0 & 1
\end{pmatrix}\\
X^3 &= \begin{pmatrix}
1 & 3a & 3b+3ac\\
0 & 1 & 3c\\
0 & 0 & 1
\end{pmatrix}\\
X^4 &= \begin{pmatrix}
1 & 4a & 4b+6ac\\
0 & 1 & 4c\\
0 & 0 & 1
\end{pmatrix}\\
X^5 &= \begin{pmatrix}
1 & 5a & 5b+10ac\\
0 & 1 & 5c\\
0 & 0 & 1
\end{pmatrix}\\
\end{align*}
etc. We notice a pattern, which is fairly straightforward, except for the coefficient of $ac$. It follows the sequence $0, 1, 3, 6, 10, \ldots$. I.e. start at $0$, add $1$, then add $2$, then add $3$, etc. We can describe the sequence recursively:
\begin{align*}
a_1 &= 0\\
a_n &= a_{n-1} + n-1
\end{align*}
We would like to derive a closed form expression for $a_n$, and thus we expand:
\begin{align*}
a_n &= a_{n-1} + n-1\\
&= a_{n-2} + (n-2) + (n-1)\\
&= a_{n-3} + (n-3) + (n-2) + (n-1)\\
&= \cdots\\
&= a_{n-(n-1)} + (n-(n-1)) + \cdots + (n-3) + (n-2) + (n-1)\\
&= a_{1} + 1 + \cdots + (n-3) + (n-2) + (n-1)\\
&= 0 + 1 + \cdots + (n-3) + (n-2) + (n-1)\\
&= 0 + 1 + 2 + 3 + \cdots + (n-3) + (n-2) + (n-1)\\
\end{align*}
This is just the standard summation of the arithmetic sequence with common difference $1$, and hence 
\begin{equation}
a_n = \frac{n(n-1)}{2}
\end{equation}
We now can derive a formula for $X^n$
\begin{lemma}\label{lemma:heisenbergpower}
Given $X = \abcberg \in H(F)$ and $n$ a nonnegative integer,
\begin{equation}
X^n =
\begin{pmatrix}
1 & na & nb+\frac{n(n-1)}{2}ac\\
0 & 1 & nc\\
0 & 0 & 1
\end{pmatrix}
\end{equation}
\end{lemma}
\begin{proof}
Base case: If $n = 0$, then this just reduces to the identity.\\
Now we suppose that 
\begin{equation}
X^{n-1} =
\begin{pmatrix}
1 & (n-1)a & (n-1)b+\frac{(n-1)(n-2)}{2}ac\\
0 & 1 & (n-1)c\\
0 & 0 & 1
\end{pmatrix}
\end{equation}
Then
\begin{align*}
X^n &= X^{n-1}X\\
&= \begin{pmatrix}
1 & (n-1)a & (n-1)b+\frac{(n-1)(n-2)}{2}ac\\
0 & 1 & (n-1)c\\
0 & 0 & 1
\end{pmatrix}
\begin{pmatrix}
1 & a & b\\
0 & 1 & c\\
0 & 0 & 1
\end{pmatrix}\\
&= \begin{pmatrix}
1 & (n-1)a + a & b+(n-1)ac+(n-1)b+\frac{(n-1)(n-2)}{2}ac\\
0 & 1 & c+(n-1)c\\
0 & 0 & 1
\end{pmatrix}\\
&= \begin{pmatrix}
1 & na & b+(n-1)b+(n-1)ac+\frac{(n-1)(n-2)}{2}ac\\
0 & 1 & nc\\
0 & 0 & 1
\end{pmatrix}\\
&= \begin{pmatrix}
1 & na & nb+(n-1)ac+\frac{(n-1)(n-2)}{2}ac\\
0 & 1 & nc\\
0 & 0 & 1
\end{pmatrix}\\
&= \begin{pmatrix}
1 & na & nb+((n-1)+\frac{(n-1)(n-2)}{2})ac\\
0 & 1 & nc\\
0 & 0 & 1
\end{pmatrix}\\
\end{align*}
Clearly, if we show that $(n-1)+\frac{(n-1)(n-2)}{2} = \frac{n(n-1)}{2}$, we're done. But
\begin{align*}
(n-1)+\frac{(n-1)(n-2)}{2} 
&= \frac{2(n-1)}{2}+\frac{(n-1)(n-2)}{2} \\
&= \frac{2(n-1) + (n-1)(n-2)}{2} \\
&= \frac{2n-2 + n^2-3n+2}{2} \\
&= \frac{n^2+2n-3n+2-2}{2} \\
&= \frac{n^2-n}{2} \\
&= \frac{n(n-1)}{2} \\
\end{align*}
\end{proof}
Now we actually find the order of each element of $H(\finfield_2)$. Note that from the previous part, $\abs{H(\finfield_2)} = \abs{\finfield_2}^3 = 2^3 = 8$, and we can exhaustively list the elements of $H(\finfield_2)$ by "turning the entries on/off":
\begin{align*}
I &= \begin{pmatrix}
1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 1
\end{pmatrix}\\
A &= \begin{pmatrix}
1 & 1 & 0\\
0 & 1 & 0\\
0 & 0 & 1
\end{pmatrix}\\
B &= \begin{pmatrix}
1 & 1 & 1\\
0 & 1 & 0\\
0 & 0 & 1
\end{pmatrix}\\
C &= \begin{pmatrix}
1 & 1 & 0\\
0 & 1 & 1\\
0 & 0 & 1
\end{pmatrix}\\
D &= \begin{pmatrix}
1 & 1 & 1\\
0 & 1 & 1\\
0 & 0 & 1
\end{pmatrix}\\
E &= \begin{pmatrix}
1 & 0 & 1\\
0 & 1 & 0\\
0 & 0 & 1
\end{pmatrix}\\
F &= \begin{pmatrix}
1 & 0 & 1\\
0 & 1 & 1\\
0 & 0 & 1
\end{pmatrix}\\
G &= \begin{pmatrix}
1 & 0 & 0\\
0 & 1 & 1\\
0 & 0 & 1
\end{pmatrix}\\
\end{align*}
Of course, $\abs{I} = 1$. Note that in for any $x \in \finfield_2$, $2x = 0$ (in fact, $nx$ for any even $n$). Now consider any element $X=\abcberg \in H(\finfield_2)$ where $ac=0$. Then following \cref{lemma:heisenbergpower},
\begin{align*}
X^2 &= \begin{pmatrix}
1 & 2a & 2b+\frac{2(2-1)}{2}ac\\
0 & 1 & 2c\\
0 & 0 & 1
\end{pmatrix}\\
&= \begin{pmatrix}
1 & 0 & 0+\frac{2(1)}{2}ac\\
0 & 1 & 0\\
0 & 0 & 1
\end{pmatrix}\\
&= \begin{pmatrix}
1 & 0 & ac\\
0 & 1 & 0\\
0 & 0 & 1
\end{pmatrix}\\
&= \begin{pmatrix}
1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 1
\end{pmatrix}\\
\end{align*}
Hence $X^2 = I$ for any $X$ where $ac=0$. Hence, 
$
\abs{A}
= \abs{B}
= \abs{E}
= \abs{F}
= \abs{G}
=2$

The only two elements left to check are $C$ and $D$, and we can actually prove the order of these elements simultaneously, by letting $b$ be arbitrary. Let
$X =
\begin{pmatrix}
1 & 1 & b\\
0 & 1 & 1\\
0 & 0 & 1
\end{pmatrix}
$. Clearly $X^1 \neq I$ and $X^2 \neq I$. Also, looking at \cref{lemma:heisenbergpower}, odd numbered exponents would make $na=n1=n$ and $nc=n$ nonzero, so we have to check the next even-numbered exponent, i.e.
\begin{align*}
X^4 &= \begin{pmatrix}
1 & 4\cdot 1 & 4b+\frac{4(4-1)}{2}1\cdot 1\\
0 & 1 & 4\cdot 1\\
0 & 0 & 1
\end{pmatrix}\\
&= \begin{pmatrix}
1 & 0 & 0+\frac{4(3)}{2}\cdot 1\\
0 & 1 & 0\\
0 & 0 & 1
\end{pmatrix}\\
&= \begin{pmatrix}
1 & 0 & 12\cdot 1\\
0 & 1 & 0\\
0 & 0 & 1
\end{pmatrix}\\
&= \begin{pmatrix}
1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 1
\end{pmatrix}\\
\end{align*}
So $\abs{X} = 4$, and $X$ could be either $C$ or $D$, so $\abs{C}=\abs{D}=4$
\item Given nonidentity $X$ in $H(\reals)$, we must have either $a\neq 0$, $b\neq 0$, or $c\neq 0$. Now, given $n \in \posints$ an integer, suppose $X^n$ is the identity matrix.  I.e. using \cref{lemma:heisenbergpower}, suppose
\begin{equation}
\begin{pmatrix}
1 & na & nb+\frac{n(n-1)}{2}ac\\
0 & 1 & nc\\
0 & 0 & 1
\end{pmatrix}
= \begin{pmatrix}
1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 1
\end{pmatrix}
\end{equation}
Which occurs iff the following system of equations holds:
\begin{align*}
na &= 0\\
nb+\frac{n(n-1)}{2}ac &= 0\\
nc &= 0
\end{align*}
We proceed by cases:
\begin{itemize}
\item Case: $a \neq 0$. Then since $n \neq 0$, the first equation cannot hold.
\item Case: $c \neq 0$. Then since $n \neq 0$, the third equation cannot hold.
\item Case: $b \neq 0$. Then consider the second equation. If it holds, then since $n$ and $b$ are both nonzero, we must have that
$\frac{n(n-1)}{2}ac \neq 0$. And in $\reals$, this means that we must have $n \neq 0$, $n-1 \neq 0$, $a \neq 0$, $c \neq 0$, but the latter two inequalities are covered in the first two cases.\\
\end{itemize}
\end{enumerate}

\skipsec{5} %SECTION 1.5

\sect{6} %SECTION 1.6
\probstmt{Let $G$ and $H$ be groups}
We start with some lemmas:

\begin{lemma}\label{lemma:6.1}
If $\phi:G\to H$ a homomorphism, then $\phi(1)=1$
\end{lemma}
\begin{proof}
Let $x\in G$. Then
\begin{align*}
\phi(x)\phi(1) &= \phi(x\cdot 1) & \mbox{$\phi$ a homomorphism}\\
&= \phi(x)\\
\implies \phi(1) &= 1 & \mbox{by left cancelation}
\end{align*}
\end{proof}

\begin{lemma}\label{lemma:6.2}
The composition of two homomorphisms is a homomorphism
\end{lemma}
\begin{proof}
Let $\phi:A\to B, \psi:B\to C$ be homomorphisms. Then given arbitrary $a,b\in A$,
\begin{align*}
\psi\comp\phi(ab) &= \psi(\phi(ab))\\
&=\psi(\phi(a)\phi(b)) & \mbox{$\phi$ a homomorphism}\\
&=\psi(\phi(a))\psi(\phi(b)) & \mbox{$\psi$ a homomorphism}\\
&=\psi\comp\phi(a)\psi\comp\phi(b)
\end{align*}
\end{proof}

\begin{lemma}\label{lemma:6.3}
If $\phi:G\to H$ is an isomorphism, its inverse map $\psi:H\to G$ is a homomorphism (and therefore is an isomorphism as well. We can therefore denote $\psi=\phiinv$.
\end{lemma}
\begin{proof}
From basic set theory, any bijection $\phi$ has a unique inverse map $\psi$, so that $\psi\comp\phi=\id$. We need to show that $\psi$ is a homomorphism. Let $h,h'\in H$. Then there are $g,g' \in G$ such that $\phi(g)=h$ and $\phi(g')=h'$. Then 
\begin{align*}
\psi(hh')&=\psi(\phi(g)\phi(g'))\\
&=\psi(\phi(gg')) & \mbox{$\phi$ is a homomorphism}\\
&=\psi\comp\phi(gg')\\
&=gg' & \mbox{$\psi$ is the inverse map}\\
&=\psi(h)\psi(h')
\end{align*}
\end{proof}

\prob{6.1}
\probstmt{Let $\phi:G\to H$ be a homomorphism.}
	\bsubprob
	\subprob{6.1}{a}
	\probstmt{Prove that $\phi(x^n) = \phi(x)^n$ for all $n \in \posints$}
	\begin{itemize}
	\item Base Case: $n=1$. Then $\phi(x^n)=\phi(x^1)=\phi(x)=\phi(x)^1=\phi(x)^n$.
	\item Induction: We assume that $\phi(x^{n-1}) = \phi(x)^{n-1}$. Then
	\begin{align*}
	\phi(x^n) &= \phi(x^{n-1}x)\\
	&=\phi(x^{n-1})\phi(x) & \mbox{$\phi$ is a homomorphism}\\
	&=\phi(x)^{n-1}\phi(x) & \mbox{Inductive hypothesis}\\
	&=\phi(x)^n 
	\end{align*}
	\end{itemize}
	\subprob{6.1}{b}
	\probstmt{Do part \ref{ex6.1a} for $n=-1$ and deduce that $\phi(x^n)=\phi(x)^n$ for all $n\in\ints$.}
	\begin{itemize}
	\item We first show this for $n=-1$:
	\begin{align*}
	\phi(x)\phi(\inv{x}) &= \phi(x\inv{x}) & \mbox{$\phi$ a homomorphism}\\
	&= \phi(1)\\
	&= 1 & \mbox{By \cref{lemma:6.1}} 
	\end{align*}
	\item Now suppose $n \in Z$ is a negative integer. Let $m \in -n$, so that $m \in \posints$. Then
\begin{align*}
\phi(x^n) &= \phi(x^{-m})\\
&= \phi(\inv{(x^m)})\\
&= \inv{\phi(x^m)} & \mbox{The $n=-1$ case}\\
&= \inv{(\phi(x)^m)} & \mbox{By \ref{ex6.1a}}\\
&= \phi(x)^{-m}\\
&= \phi(x)^n
\end{align*}
	\item The $n=0$ case is obvious, via \cref{lemma:6.1}: $\phi(x^0)=\phi(1)=1=\phi(x)^0$
	\end{itemize}
	\esubprob
\prob{6.2}
\probstmt{If $\phi:G\to H$ is an isomorphism, prove that $\abs{\phi(x)}=\abs{x}$ for all $x\in G$. Deduce that any two isomorphic groups have the same number of elements of order $n$ for each $n\in\posints$. Is the result true if $\phi$ is only assumed to be a homomorphism?}
	Let $x\in G$ and denote $\abs{\phi(x)}=n$, $\abs{x}=k$. Then
	\begin{align*}
	x^k &= 1\\
	\implies \phi(x^k) &= \phi(1)\\
	\implies \phi(x)^k &= 1\\
	\implies n \leq k
	\end{align*}
	But
	\begin{align*}
	\phi(x)^n &= 1\\
	\implies \phi(x^n) &= 1\\
	\implies x^n &= \phiinv(1) & \mbox{$\phi$ is an isomorphism}\\
	&= 1
	\end{align*}
	so $k \leq n$. Hence, $k=n$.\\
	The fact that two isomorphic groups have the same elements of order for each positive integer follows trivially. If $\phi$ is only a homomorphism, the result is not necessarily true: Consider the trivial homomorphism $G\to\set{1}$ where $G$ has elements of order $>1$
\prob{6.3}
\probstmt{If $G\to H$ is an isomorphism, prove that $G$ is abelian if and only if $H$ is abelian. If $\phi:G\to H$ is a homorphism, what additional conditions on $\phi$ (if any) are sufficient to ensure that if $G$ is abelian, then so is $H$?}
\begin{itemize}
\item $\implies$: Let $G$ be abelian. Then given $h,h'\in H$ there are $g,g'$ s.t. $\phi(g)=h,\phi(g')=h'$ (since $\phi$ is an isomoprhism). Then 
\begin{align*}
hh' &= \phi(g)\phi(g')\\
&= \phi(gg')\\
&= \phi(g'g) & \mbox{$G$ abelian}\\
&= \phi(g')\phi(g)\\
&= h'h
\end{align*}
Since $h,h'\in H$ were arbitrary, $H$ is abelian.
\item $\impliedby$: Apply the same proof with $\phiinv$ instead of $\phi$
\item For an arbitrary homomorphism $\phi$, it suffices for $\phi$ to be surjective (The proof above works, because we can select $g\in\phiinv(h),g'\in\phiinv(h')$.
\end{itemize}
\prob{6.4}
\probstmt{Prove that the multiplicative groups $\reals-\set{0}$ and $\complex-\set{0}$ are not isomorphic.}
Note that $\abs{e^{\frac{2\pi}{7}i}}=7$, but $\reals-\set{0}$ only has elements of order $1,2,\infty$. Apply \exref{6.2}
\prob{6.5}
\probstmt{Prove that the additive groups $\reals$ and $\rats$ are not isomorphic.}
$\reals$ is uncountable and $\rats$ is countable. By basic theory, not even a bijection exists between them.
\prob{6.6}
\probstmt{Prove that the additive groups $\ints$ and $\rats$ are not isomorphic.}
Suppose $\phi: \ints\to\rats$ was an isomorphism. Then given $n\in\ints$, apply \exref{6.1}: $\phi(n)=\phi(1n)=n\phi(1)=n\cdot 1=n$. So $\phi$ only maps onto the integers and therefore is not surjective onto $\rats$.
\skipprob{6.7}
\skipprob{6.8}
\skipprob{6.9}
\skipprob{6.10}
\prob{6.11}
\probstmt{Let $A$ and $B$ be groups. Prove that $A\times B \iso B \times A$.}
The map $(a,b) \mapsto (b,a)$ is clearly an isomorphism. 
\prob{6.12}
\probstmt{Let $A,B$, and $C$ be groups and let $G=A\times B$ and $H=B\times C$. Prove that $G\times C \iso A\times H$.}
Clearly the map $((a,b),c) \mapsto (a,(b,c))$ is an isomorphism.
\prob{6.13}
\probstmt{Let $G$ and $H$ be groups and let $\phi: G\to H$ be a homomorphism. Prove that the image of $\phi$, $\phi(G)$, is a subgroup of $H$ (cf. Exercise of Section 1). Prove that if $\phi$ is injective then $G\iso\phi(G)$.}
\begin{itemize}
\item Closed under the operation: If $h,h' \in \phi(G)$, then $\exists g,g'\in G$ such that $\phi(g)=h, \phi(g')=h'$. And $hh'=\phi(g)\phi(g')=\phi(gg')\in\phi(G)$.
\item Closed under inverses: If $h\in\phi(G)$, then $\exists g\in G$ s.t. $\phi(g)=h$. Let $h'=\phi(\inv{g})$, and note that $h'\in\phi(G)$. And $hh'=\phi(g)\phi(\inv{g})=\phi(g\inv{g})=\phi(1)=1$. So $h'=\inv{h}$ and $\inv{h}\in\phi(G)$.
\item $\phi$ is trivially surjective onto $\phi(G)$. If it's also injective, that makes it bijective and therefore an isomorphism (onto $\phi(G)$).
\end{itemize}
\prob{6.14}
\probstmt{Let $G$ and $H$ be groups and let $\phi:G\to H$ be a homomorphism. Define the \emph{kernel} of $\phi$ to be $\set{g\in G | \phi(g) = 1_H }$ (so the kernel is the set of elements in $G$ which map to the identity of $H$, i.e., is the fiber over the identity of $G$, i.e., is the fiber over the identity of $H$). Prove that the kernel of $\phi$ is a subgroup (cf. Exercise 26 of Section 1) of $G$. Prove that $\phi$ is injective if and only if the kernel of $\phi$ is the identity subgroup of $G$.}
\begin{enumerate}[(1)]
\item We first show that $\ker\phi$ is a subgroup.
\begin{itemize}
\item Closure under the operation: Let $g,g'\in \phiinv(1)$. Then
\begin{align*}
\phi(gg') &= \phi(g)\phi(g')\\
&= 1\cdot 1\\
&= 1\\
\implies gg' &\in \phiinv(1)
\end{align*}
\item Closure under inverse. Given $g\in\phiinv(1)$. we note that
\begin{align*}
\phi(\inv{g}) &= \inv{\phi(g)}\\
&= \inv{1}\\
&= 1\\
\implies \inv{g} &\in \phiinv(1)
\end{align*}
\end{itemize}
\item Now we show that $\phi$ is injective $\iff$ $\phiinv(1) = \set{1}$. Let's prove a lemma

\begin{lemma}\label{lemma:6.4}
$\phi:G\to H$ is injective if and only if $\forall g\in G: \phi(g) = 1 \implies g=1$
\end{lemma}
\begin{proof}
The definition of an injective map is $\phi(g)=\phi(h)\implies g=h$.
\begin{itemize}
\item $\implies$: Suppose $\phi$ is injective. Note that since $\phi$ is a homomorphism, $\phi(1) = 1$ by \cref{lemma:6.1}. But $\phi(g)=1$. So we must have have $g=1$ because $\phi$ is injective.
\item $\impliedby$: Let $g,h \in G$. Then
\begin{align*}
\phi(g) &= \phi(h)\\
\implies 1 &= \phi(h)\inv{\phi(g)}\\
&= \phi(h)\phi(\inv{g})\\
&= \phi(h\inv{g})\\
\implies 1&= h\inv{g}\\
\implies g &= h
\end{align*}
Since $g,h$ were arbitrary, $\phi$ is injective
\end{itemize}
\end{proof}
Now we proceed with the exercise
\begin{itemize}
\item $\implies$: Suppose $\phi$ injective. Then given $g\in G$,
\begin{align*}
\phi(g) &= 1\\
&= \phi(1) & \mbox{by \cref{lemma:6.1}}\\
\implies g &= 1 & \mbox{by \cref{lemma:6.4}}
\end{align*}
Since $g$ was arbitrary, we have $\phiinv(1) = \set{1}$.
\item $\impliedby$: Suppose $\phiinv(1)=\set{1}$. Then given $g\in G$,
\begin{align*}
\phi(g) &= 1\\
\implies g &\in \phiinv(1)\\
\implies g &= 1 & \mbox{by the condition}
\end{align*}
Hence \cref{lemma:6.4} gives us injectivity.
\end{itemize}
\end{enumerate}
\prob{6.15}
\probstmt{Define a map $\pi: \reals^2 \to \reals$ by $\phi((x,y))=x$. Prove that $\pi$ is a homomorphism and find the kernel of $\pi$ (cf. Exercises \ref{ex6.14}).}
\begin{itemize}
\item Let $(x,y),(a,b) \in \reals^2$. Then $\pi((x,y)(a,b)) = \pi(xa,yb) = xa = \pi(x,a)\pi(y,b)$. Thus, $\pi$ is a homomorphism.
\item If we have $\pi(x,y) = 1$, then we must have $x \in 1$. Hence $\ker\pi=\set{(1,y)|y\in\reals}$.
\end{itemize}
\prob{6.16}
\probstmt{Let $A$ and $B$ be groups and let $G$ be their direct product, $A\times B$. Prove that the maps $\pi_1: G\to A$ and $\pi_2: G\to B$ defined by $\pi_1((a,b))=a$ and $\pi_2((a,b))=b$ are homomorphisms and find their kernels.}
The demonstration that they are homomorphisms is analagous to the previous exercise. The kernels are also analagous
\prob{6.17}
\probstmt{Let $G$ be any group. Prove that the map from $G$ to itself defined by $g \mapsto \inv{g}$ is a homomorphism if and only if $G$ is abelian.}
Denote the map as $\phi$
\begin{itemize}
\item $\implies$: Suppose $\phi$ a homomorphism. Then
\begin{align*}
gh &= \phi(\inv{g})\phi(\inv{h})\\
&= \phi(\inv{g}\inv{h})\\
&= \phi(\inv{(hg)})\\
&= hg & \mbox{Definition of $\phi$}
\end{align*}
Hence $G$ is abelian
\item $\impliedby$: Suppose $G$ is abelian. Then 
\begin{align*}
\phi(gh)&=\inv{(gh)}\\
&=\inv{h}\inv{g}\\
&=\inv{g}\inv{h} & \mbox{$G$ abelian}\\
&=\phi(g)\phi(h)
\end{align*}
Hence, $\phi$ is a homomorphism.
\end{itemize}
\prob{6.18}
\probstmt{Let $G$ be any group. Prove that the map from $G$ to itself defined by $g\mapsto g^2$ is a homomorphism if and only if $G$ is abelian.}
Denote the map as $\phi$
\begin{itemize}
\item $\implies$: Suppose $\phi$ is a homomorphism. Let $g,h \in G$. Then
\begin{align*}
gh &= 1gh1\\
&= \inv{g}gghh\inv{h}\\
&= \inv{g}g^2h^2\inv{h}\\
&= \inv{g}\phi(g)\phi(h)\inv{h}\\
&= \inv{g}\phi(gh)\inv{h} & \mbox{$\phi$ homomorphism}\\
&= \inv{g}(gh)^2\inv{h}\\
&= \inv{g}ghgh\inv{h}\\
&= 1hg1\\
&= hg
\end{align*}
Hence, $G$ is abelian.
\item $\impliedby$: Suppose $G$ is abelian. Then given $g,h\in G$,
\begin{align*}
\phi(gh) &= (gh)^2\\
&= ghgh\\
&= gghh & \mbox{$G$ abelian}\\
&= g^2h^2\\
&= \phi(g)\phi(h)
\end{align*}
So $\phi$ is a homomorphism.
\end{itemize}
\prob{6.19}
\probstmt{Let $G=\set{z\in\complex | z^n = 1 \mbox{ for some } n\in\posints}$. Prove that for any fixed integer $k>1$ the map from $G$ to itself defined by $z \mapsto z^k$ is a surjective homomorphism but is not an isomorphism}
Fix $k>1$ an integer and denote the homomorphism by $\phi$. Let $z\in G$. Then $\exists n \in \posints$ such that $z^n=1$. We write $z=re^{xi}$, and assume \wlg that $r \geq 0$. Then
\begin{align*}
z^n &= 1\\
\implies (re^{xi})^n &= 1\\
\implies r^ne^{xni} &= 1e^{0i}
\end{align*}
So we must have $r=1$ and, for some $m\in\ints$, we have $xn=2\pi m$. Dividing by $n$ on both sides yields
\begin{equation}
x = \frac{2\pi m}{n}
\end{equation}
We want $l$ such that
\begin{align*}
\phi(l) &= z\\
\implies (re^{yi})^k &= e^{\frac{2\pi m}{n}i}\\
\implies r^ke^{yki} &= 1e^{\frac{2\pi m}{n}i}\\
\end{align*}
So we must have $r=1$ and also 
\begin{align*}
yk &= \frac{2\pi m}{n}\\
\implies y&= \frac{2\pi m}{nk}
\end{align*}
Hence, $l=e^{\frac{2\pi m}{nk}} \mapsto z$ under $\phi$ (Note that $l^{nk}=1$ as well, so $l\in G$). Since $z\in G$ was arbitrary, $\phi$ is surjective.\\
Also note that $e^{\frac{2\pi}{k}i}, e^{\frac{4\pi}{k}i} \in G$ are not equal, but they both map to $1$ under $\phi$.
\prob{6.20}
\probstmt{Let $G$ be a group and let $\Aut(G)$ be the set of all isomorphisms from $G$ onto $G$. Prove that $\Aut(G)$ is a group under function composition (called the \emph{automorphism group} of $G$ and the elements of $\Aut(G)$ are called \emph{automorphisms} of $G$}
\begin{itemize}
\item $\Aut G$ has an identity since the identity map is an isomorphism.
\item If $\phi$ is an isomorphism, it has an inverse isomorphism by \cref{lemma:6.3}.
\item $\Aut G$ is closed under composition by \cref{lemma:6.2}
\item Associativity: Let $\phi,\psi,\delta\in\Aut G$, and let $g\in G$. Then
\begin{align*}
\phi\comp(\psi\comp\delta)(g) &= \phi(\psi\comp\delta(g))\\
&= \phi(\psi(\delta(g)))\\
&= \phi\comp\psi(\delta(g))\\
&= (\phi\comp\psi)\comp\delta(g)
\end{align*}
Since $g\in G$ was arbitrary, we have $\phi\comp(\psi\comp\delta)=(\phi\comp\psi)\comp\delta$
\end{itemize}
\prob{6.21}
\probstmt{Prove that for each fixed nonzero $k\in\rats$ the map from $\rats$ to itself defined by $q\mapsto kq$ is an automorphism of $\rats$ (cf. Exercise \ref{ex6.20}).}
Fix nonzero $k\in\rats$. Denote the homomorphism by $\phi$. Let $q,p\in Q$. Then $\phi(q+p) = k(q+p) =kq+kp=\phi(q)+\phi(p)$, so $\phi$ is a homomorphism. Note that we must have $k\neq 0$ and $1/k\in \rats$, and the inverse map $q\mapsto \frac{1}{k}q$ makes $\phi$ a bijection, and therefore an automorphism.
\prob{6.22}
\probstmt{Let $A$ be an abelian group and fix some $k\in\ints$. Prove that the map $a \mapsto a^k$ is a homomorphism from $A$ to itself. If $k=-1$ prove that this homomorphism is an isomorphism (i.e., is an automorphism of $A$).}
\begin{itemize}
\item Denote the homomorphism $\phi$. Then
\begin{align*}
\phi(ab) &= (ab)^k\\
&= a^kb^k & \mbox{$A$ abelian}\\
&= \phi(a)\phi(b)
\end{align*}
so $\phi$ is a homomorphism
\item Suppose $k=-1$. Then clearly $\phi$ is an inverse homomorphism for itself.
\end{itemize}
\end{document}



